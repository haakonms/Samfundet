{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idasand/Samfundet/blob/master/unetUPDATED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yvopUZ04m1rt",
        "colab_type": "code",
        "outputId": "3501e05d-7686-4afc-8405-8ba604f2ca7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import shutil\n",
        "import sys\n",
        "import urllib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow.python.platform\n",
        "import tensorflow as tf\n",
        "from scipy import misc, ndimage\n",
        "import shutil\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "\n",
        "\n",
        "from mask_to_submission import *\n",
        "from helpers import *\n",
        "from image_processing import *\n",
        "from image_augmentation import *\n",
        "from F1_metrics import *\n",
        "from data_extraction import *\n",
        "from prediction import *\n",
        "from unet_pred import *\n",
        "from unetModel import *\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3 # RGB images\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 2\n",
        "TRAINING_SIZE = 100\n",
        "TESTING_SIZE = 50\n",
        "VALIDATION_SIZE = 0  # Size of the validation set.\n",
        "SEED = 66478  # Set to None for random seed.\n",
        "BATCH_SIZE = 16 # 64\n",
        "NUM_EPOCHS = 5\n",
        "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
        "RECORDING_STEP = 1000\n",
        "MAX_AUG = 6\n",
        "NEW_DIM_TRAIN = 400\n",
        "\n",
        "# The size of the patches each image is split into. Should be a multiple of 4, and the image\n",
        "# size would be a multiple of this. For this assignment to get the delivery correct it has to be 16\n",
        "IMG_PATCH_SIZE = 16\n",
        "INPUT_CHANNELS = 3\n",
        "\n",
        "# Extract data into numpy arrays, divided into patches of 16x16\n",
        "data_dir = '/content/drive/My Drive/data/'\n",
        "train_data_filename = data_dir + 'training/images/'\n",
        "train_labels_filename = data_dir + 'training/groundtruth/' \n",
        "test_data_filename = data_dir + 'test_set_images'\n",
        "\n",
        "# Directive for storing the augmented training images\n",
        "imgDir = 'training/augmented/images'\n",
        "groundTruthDir = 'training/augmented/groundtruth'\n",
        "\n",
        "\n",
        "\n",
        "#earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/helpers.py:9: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use('Agg')\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNnxJo5knjlQ",
        "colab_type": "code",
        "outputId": "aca890e2-4fc6-430f-e129-a89f94619a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "#x_train, y_train, x_test = load_data_img(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "#x_train, y_train, x_test = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "\n",
        "x_train, y_train, x_test, x_val, y_val = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE,VALIDATION_SIZE, NEW_DIM_TRAIN,\n",
        "  saltpepper = 0.0,augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting training images...\n",
            "Test data shape:  (50, 608, 608, 3)\n",
            "Number of samples in class 1 (background):  85997392\n",
            "Number of samples in class 2 (road):  26002608 \n",
            "\n",
            "(700, 400, 400, 2)\n",
            "(700, 400, 400, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25DNYPNgnkP3",
        "colab_type": "code",
        "outputId": "eaa970d2-d267-4a95-a5a9-64d1d596f1ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Class weigths\n",
        "classes = np.array([0,1])\n",
        "class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,:,:,0].flatten())\n",
        "print('Class weights: ',class_weights) \n",
        "'''\n",
        "yweight = y_train[:,:,:,0]\n",
        "yweight = yweight.flatten()\n",
        "print(np.unique(yweight), sum(yweight))\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(yweight),\n",
        "                                                 yweight)'''\n",
        "\n",
        "print('Class weights: ',class_weights) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class weights:  [0.65118254 2.15363013]\n",
            "Class weights:  [0.65118254 2.15363013]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jds_lu_roHgs",
        "colab_type": "code",
        "outputId": "134a06e6-d62d-4a84-b5f2-2e6f2165bbb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2788
        }
      },
      "cell_type": "code",
      "source": [
        "#model = ZF_UNET_224(class_weights,NEW_DIM_TRAIN)\n",
        "inputs = Input((NEW_DIM_TRAIN, NEW_DIM_TRAIN,INPUT_CHANNELS))\n",
        "model = create_model(inputs,n_filters=16, dropout=0.05)\n",
        "model.summary()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 400, 400, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 400, 400, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 400, 400, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 400, 400, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 400, 400, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 400, 400, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 200, 200, 16) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 32) 4640        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 32) 9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 32) 128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 32) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 100, 100, 32) 0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 100, 32) 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 100, 100, 64) 18496       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 100, 100, 64) 256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 100, 100, 64) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 100, 100, 64) 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 100, 100, 64) 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 100, 100, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 50, 50, 64)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 50, 50, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 50, 50, 128)  73856       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 50, 50, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 50, 50, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 50, 50, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 50, 50, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 50, 50, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 25, 25, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 25, 25, 128)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 256)  295168      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 50, 50, 128)  295040      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 50, 50, 256)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 50, 50, 256)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 50, 50, 128)  295040      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 50, 50, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 50, 50, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 50, 50, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 50, 50, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 50, 50, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 100, 100, 64) 73792       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 100, 100, 128 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 100, 100, 128 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 73792       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 100, 100, 64) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 64) 36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 100, 100, 64) 256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 100, 100, 64) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 200, 200, 32) 18464       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 200, 200, 64) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 200, 200, 64) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 200, 200, 32) 18464       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 200, 200, 32) 128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 200, 200, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 200, 200, 32) 9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 200, 200, 32) 128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 200, 200, 32) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 400, 400, 16) 4624        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 400, 400, 32) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 400, 400, 32) 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 400, 400, 16) 4624        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 400, 400, 16) 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 400, 400, 16) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 400, 400, 16) 2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 400, 400, 16) 64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 400, 400, 16) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 400, 400, 2)  34          activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,164,610\n",
            "Trainable params: 2,161,666\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HE_56DAEoMRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H88mDhTgoVFW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checkpoint\n",
        "filepath=\"/content/drive/My Drive/weightsUnet/weights.best.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#callbacks_list = [checkpoint]\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True,mode='max')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FF6dhzigojnd",
        "colab_type": "code",
        "outputId": "a4bfcb7b-322b-4e08-a42e-af6f57992abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "630/630 [==============================] - 55s 88ms/step - loss: 0.5568 - acc: 0.7227 - val_loss: 1.2770 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71815, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.3557 - acc: 0.8491 - val_loss: 0.3796 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71815 to 0.85996, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.2927 - acc: 0.8780 - val_loss: 0.4214 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.85996\n",
            "Epoch 4/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.2611 - acc: 0.8921 - val_loss: 0.3751 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.85996 to 0.86271, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.2366 - acc: 0.9009 - val_loss: 0.3605 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.86271 to 0.86890, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b5bdd6e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "G71c9o5UwVRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "f54080fd-87b3-46a6-ee09-1d33f2ec549f"
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.2195 - acc: 0.9080 - val_loss: 0.2850 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.86890 to 0.89443, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.2039 - acc: 0.9152 - val_loss: 0.2846 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.89443\n",
            "Epoch 3/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1956 - acc: 0.9193 - val_loss: 0.2763 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.89443 to 0.90251, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1809 - acc: 0.9252 - val_loss: 0.4525 - val_acc: 0.8668\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.90251\n",
            "Epoch 5/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1753 - acc: 0.9279 - val_loss: 0.4205 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.90251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b5bdd6b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "wkFNIb4fwWBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "b76c1a48-1e42-46a0-8f0b-3f12a7df21d1"
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1619 - acc: 0.9335 - val_loss: 0.1973 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.90251 to 0.92386, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1547 - acc: 0.9361 - val_loss: 0.3008 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92386\n",
            "Epoch 3/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1552 - acc: 0.9356 - val_loss: 0.2112 - val_acc: 0.9184\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92386\n",
            "Epoch 4/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1460 - acc: 0.9396 - val_loss: 0.1977 - val_acc: 0.9272\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.92386 to 0.92723, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1400 - acc: 0.9425 - val_loss: 0.1978 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b5981d668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "qWQ30vt-wWkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "0dc30790-8136-43b8-e85f-89d64b6420d9"
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1498 - acc: 0.9380 - val_loss: 0.2425 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.92723\n",
            "Epoch 2/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1384 - acc: 0.9428 - val_loss: 0.1703 - val_acc: 0.9342\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.92723 to 0.93419, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1249 - acc: 0.9481 - val_loss: 0.1841 - val_acc: 0.9284\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.93419\n",
            "Epoch 4/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1234 - acc: 0.9488 - val_loss: 0.1786 - val_acc: 0.9318\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.93419\n",
            "Epoch 5/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1237 - acc: 0.9483 - val_loss: 0.1863 - val_acc: 0.9258\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.93419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b5bdbaef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "GnYfs2fKwXIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b3e496fa-de9c-4557-a4c6-70873e822cf5"
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "vyYuUaV40eKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "24aed5f3-a332-44b1-9340-86c9e7593479"
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "4aMxiZQd0esg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c76e7dfd-5d87-40e1-894b-03eb4eb82e40"
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "VBnpSrKMo0-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "94d826da-6ab2-44ce-aca3-e1af9af40e1e"
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yF3QeOmXo2J8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "02c5fd6b-cf13-44e5-bc87-eaacceb148f1"
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1169 - acc: 0.9510 - val_loss: 0.1660 - val_acc: 0.9374\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.93419 to 0.93738, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1096 - acc: 0.9545 - val_loss: 0.1595 - val_acc: 0.9374\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.93738 to 0.93745, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1068 - acc: 0.9552 - val_loss: 0.1495 - val_acc: 0.9402\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.93745 to 0.94021, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1053 - acc: 0.9560 - val_loss: 0.1474 - val_acc: 0.9422\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.94021 to 0.94217, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.0985 - acc: 0.9586 - val_loss: 0.1475 - val_acc: 0.9418\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.94217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b5981d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "9K2TCddqo2rU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "dccaafd5-72fd-4c82-ef5a-6731357e8ffa"
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.0999 - acc: 0.9579 - val_loss: 0.1813 - val_acc: 0.9314\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.94217\n",
            "Epoch 2/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.1037 - acc: 0.9561 - val_loss: 0.1620 - val_acc: 0.9399\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.94217\n",
            "Epoch 3/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.0948 - acc: 0.9601 - val_loss: 0.1455 - val_acc: 0.9419\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.94217\n",
            "Epoch 4/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.0876 - acc: 0.9631 - val_loss: 0.1496 - val_acc: 0.9406\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.94217\n",
            "Epoch 5/5\n",
            "630/630 [==============================] - 42s 67ms/step - loss: 0.0916 - acc: 0.9615 - val_loss: 0.1622 - val_acc: 0.9388\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.94217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b59907a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "S3bZxT8-o7A6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b9b5c607-821c-4086-d971-01d8ba990393"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "list_filename = []\n",
        "prediction_test_dir = \"/content/drive/My Drive/predictions_test/\"\n",
        "GT_pred_test_dir = \"/content/drive/My Drive/predictions_ground_test/\"\n",
        "\n",
        "if not os.path.isdir(prediction_test_dir):\n",
        "    os.mkdir(prediction_test_dir)\n",
        "if not os.path.isdir(GT_pred_test_dir):\n",
        "    os.mkdir(GT_pred_test_dir)\n",
        "    \n",
        "y_submit = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "  gt_pred, orImg = get_pred_img_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN,prediction_test_dir)\n",
        "  gt_filename = GT_pred_test_dir + \"gt_pred_\" + str(i) + \".png\"\n",
        "  list_filename.append(gt_filename)\n",
        "  gt_pred.save(gt_filename)\n",
        "  overlay2 = make_img_overlay_pixel(orImg, gt_pred, PIXEL_DEPTH)\n",
        "  overlay2.save(GT_pred_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "  ## FOR OWN VALIDATION ONLY, NEED IT TO COUNT WHITE PATCHES\n",
        "  gtarr = np.asarray(gt_pred)\n",
        "  label_patches = img_crop(gtarr, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "  data = np.asarray(label_patches)\n",
        "  labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "  newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "  img = Image.fromarray(newPred)\n",
        "  img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "  y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "  overlay = make_img_overlay_pixel(orImg, img, PIXEL_DEPTH)\n",
        "  overlay.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "  \n",
        "print('y_submit: ', y_submit.shape)\n",
        "print('antall vei / antall bakgrunn: ', np.sum(y_submit[:,1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_submit:  (72200, 2)\n",
            "antall vei / antall bakgrunn:  27323.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RDdQiDP9wVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "masks_to_submission(\"kerasMask.csv\", *list_filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63_NL11kpFz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_training_dir = \"/content/drive/My Drive/predictions_training/\"\n",
        "\n",
        "if not os.path.isdir(prediction_training_dir):\n",
        "    os.mkdir(prediction_training_dir)\n",
        "for i in range(1, TRAINING_SIZE+1):\n",
        "    oimg, imgpred = get_prediction_with_overlay_pixelwise(train_data_filename, i, 'train', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE)\n",
        "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    imgpred.save(prediction_training_dir + \"predictimg_\" + str(i) + \".png\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bAe23oNqxCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2723594b-951d-43f5-94c7-f9ad81942584"
      },
      "cell_type": "code",
      "source": [
        "# UNNECESSARY\n",
        "# Make submission file\n",
        "prediction_to_submission2('submission_keras.csv', y_submit)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72200, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ybd8Rc-DAKVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**POST-PROCESSING**"
      ]
    },
    {
      "metadata": {
        "id": "rKyKVhNcAyvQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_test_filename = '/content/drive/My Drive/test_set_post_images/'\n",
        "post_processed_list = []\n",
        "if not os.path.isdir(new_test_filename):\n",
        "    os.mkdir(new_test_filename)\n",
        "\n",
        "#y_submit_post = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "    p_img = get_postprocessed_unet(GT_pred_test_dir, i, 'test')\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    post_processed_list.append(filename)\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")\n",
        "\n",
        "masks_to_submission(\"kerasPostprocessedMask.csv\", *post_processed_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrLv8aPReNcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "2521f4ad-f1b6-4b4d-c3a2-0a3af9352ba4"
      },
      "cell_type": "code",
      "source": [
        "  y_pred_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  y_val_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  for i in range(VALIDATION_SIZE):\n",
        "    x_img = x_val[i,:,:,:]\n",
        "    x_img = Image.fromarray(x_img)\n",
        "    output_prediction = get_prediction_pixel(x_img, model, NEW_DIM_TRAIN) #(1,224,224)\n",
        "    output_prediction = np.transpose(output_prediction, (1, 2, 0)) #(224,224,1)\n",
        "    predict_img = np.asarray(output_prediction)\n",
        "\n",
        "    # Changes into a 3D array, to easier turn into image\n",
        "    predict_img_3c = np.zeros((predict_img.shape[0],predict_img.shape[1], 3), dtype=np.uint8)\n",
        "    predict_img8 = np.squeeze(img_float_to_uint8(predict_img, PIXEL_DEPTH))\n",
        "    predict_img8[predict_img8 >= 100] = 255 \n",
        "    predict_img8[predict_img8 < 100] = 0        \n",
        "    predict_img_3c[:,:,0] = predict_img8\n",
        "    predict_img_3c[:,:,1] = predict_img8\n",
        "    predict_img_3c[:,:,2] = predict_img8\n",
        "    #imgpred = Image.fromarray(predict_img_3c)\n",
        "    label_patches = img_crop(predict_img_3c, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    data = np.asarray(label_patches)\n",
        "    labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "    #newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "    #img = Image.fromarray(newPred)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    y_pred_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = labels\n",
        "    print(labels.shape)\n",
        "    y_label_patches = img_crop(y_val[i,:,:,:], IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    y_data = np.asarray(y_label_patches)\n",
        "    y_labels = np.asarray([value_to_class(np.mean(y_data[i])) for i in range(len(y_data))])\n",
        "    y_val_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = y_labels\n",
        "\n",
        "  \n",
        "  \n",
        "tp, tn, fp, fn = f1_values(y_pred_train, y_val_train[:,1])\n",
        "f1 = f1_measure(tp, fp, fn)\n",
        "print(\"f1\", f1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No predicted roads!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-15c047ed815f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/F1_metrics.py\u001b[0m in \u001b[0;36mf1_measure\u001b[0;34m(tp, fp, fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/F1_metrics.py\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(tp, fp)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No predicted roads!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TZ7GEXMrOu1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1,TESTING_SIZE+1):\n",
        "    #test_data_filename = data_dir + 'test_set_images'\n",
        "    \n",
        "    #oimg, gtimg = get_prediction_with_overlay_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN)\n",
        "    #oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    y_submit_post[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:], p_img = get_pred_postprocessed_unet(prediction_test_dir, i, 'test',IMG_PATCH_SIZE)\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    orImg = Image.open(image_filename)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    print(np.asarray(pred).shape)\n",
        "    print(np.asarray(p_img).shape)\n",
        "    #y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}