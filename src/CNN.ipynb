{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN model from scratch\n",
    "\n",
    "This notebook is created to train the model with the CNN architecture from scratch. When the model is trained, prediction is done on the given test images, and the submission file is saved to 'submission.csv'. A post-processing step is also implemented, and the result after this is done is saved in 'submission_pp.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "_uedmAiL3C2D",
    "outputId": "e87c7016-08d6-4c7f-ebee-f26bb3a1c3c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow.python.platform\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "from mask_to_submission import masks_to_submission\n",
    "from cnn_pred import get_prediction_with_overlay_context, get_predictionimage_context, get_pred_postprocessed, make_img_overlay\n",
    "from data_extraction import load_data_context\n",
    "from cnn_model import create_model_cnn\n",
    "\n",
    "\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 100\n",
    "TESTING_SIZE = 50\n",
    "VALIDATION_SIZE = 10  # Size of the validation set.\n",
    "\n",
    "BATCH_SIZE = 16 \n",
    "NUM_EPOCHS = 100\n",
    "MAX_AUG = 2\n",
    "IMG_PATCH_SIZE = 16\n",
    "CONTEXT_SIZE = 16\n",
    "NOISE_LEVEL = 0.006\n",
    "\n",
    "\n",
    "'''Image paths'''\n",
    "data_dir = '../data/'\n",
    "train_data_filename = data_dir + 'training/images/'\n",
    "train_labels_filename = data_dir + 'training/groundtruth/' \n",
    "test_data_filename = data_dir + 'test_set_images'\n",
    "\n",
    "\n",
    "'''Path for storing the augmented training images'''\n",
    "aug_img_path = data_dir +'training/augmented/images'\n",
    "aug_gt_path = data_dir + 'training/augmented/groundtruth'\n",
    "\n",
    "\n",
    "'''Path to store best weights and the submission file, and the predicted images'''\n",
    "weight_path = '../weights/'\n",
    "weight_filename = 'chechpoint.weights.cnn.hdf5'\n",
    "submission_path = '../submission.csv'\n",
    "pred_test_path = '../predictions_test/'\n",
    "\n",
    "\n",
    "'''Path to store results after post-processing'''\n",
    "postprocess_path = '../predictions_test_pp/'\n",
    "pp_submission_path = '../submission_pp.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3tcLwM-m3C32",
    "outputId": "7e0f17fa-ced1-46b9-df3e-140c1827cc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training images...\n",
      "Directory  ../data/training/augmented/images  already exists, overwritten\n",
      "Directory  ../data/training/augmented/groundtruth  already exists, overwritten\n",
      "Loading test images\n",
      "\n",
      "Train data shape:  (12500, 48, 48, 3)\n",
      "Train labels shape:  (12500, 2)\n",
      "Test data shape:  (14440, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, x_val, y_val = load_data_context(train_data_filename, train_labels_filename,\n",
    "          test_data_filename, TRAINING_SIZE, VALIDATION_SIZE, IMG_PATCH_SIZE, CONTEXT_SIZE, TESTING_SIZE,\n",
    "          saltpepper = NOISE_LEVEL, augment=True, MAX_AUG=MAX_AUG, augImgDir=aug_img_path , data_dir=data_dir, groundTruthDir =aug_gt_path, newaugment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_list = [i for i in range(y_train.shape[0])]\n",
    "shuffle(ind_list)\n",
    "x_train  = x_train[ind_list, :,:,:]\n",
    "y_train = y_train[ind_list,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "muzLk7zL3C3-",
    "outputId": "3618b12a-01d0-41a7-9d64-f67a982ac2ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  [0.70185289 1.73852573]\n"
     ]
    }
   ],
   "source": [
    "classes = np.array([0,1])\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,1])\n",
    "\n",
    "print('Class weights: ',class_weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "NfA3idKI3C4D",
    "outputId": "751be8d3-9a3c-478b-a242-3df4bd16bc5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 252)       290556    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 252)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 252)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1161344   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,527,806\n",
      "Trainable params: 1,527,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows = x_train[0].shape[1]\n",
    "img_cols = img_rows\n",
    "input_shape = (img_rows, img_cols, NUM_CHANNELS) \n",
    "\n",
    "model = create_model_cnn(input_shape, NUM_LABELS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YL-lqc7P3C4H"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "          optimizer=Adam(),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining chechpoints to ensure the best weights are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEPiNE-03C4L"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(weight_path):\n",
    "    os.mkdir(weight_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path+weight_filename, monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "RsxBSm4y3C4T",
    "outputId": "afd4ed44-2862-4504-d1d5-44735fb9c369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 1875 samples\n",
      "Epoch 1/1\n",
      "12500/12500 [==============================] - 189s 15ms/step - loss: 0.4900 - acc: 0.7528 - val_loss: 0.3638 - val_acc: 0.8384\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83840, saving model to ../weights/chechpoint.weights.cnn.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd2d9d3a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          shuffle = True,\n",
    "          verbose=1,\n",
    "          class_weight = class_weights,\n",
    "          callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best weights from the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dDiZAi8l3C4d",
    "outputId": "ca39b98a-8f00-4475-9e98-98fb9f4adf61"
   },
   "outputs": [],
   "source": [
    "model.load_weights(weight_path+weight_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the test images, and creating overlay and groundtruth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission...\n",
      "10 % done\n",
      "20 % done\n",
      "30 % done\n",
      "40 % done\n",
      "50 % done\n",
      "60 % done\n",
      "70 % done\n",
      "80 % done\n",
      "90 % done\n",
      "100 % done\n"
     ]
    }
   ],
   "source": [
    "print('Creating submission...')\n",
    "if not os.path.isdir(pred_test_path):\n",
    "    os.mkdir(pred_test_path)\n",
    "    \n",
    "filenames = []\n",
    "for i in range(1,TESTING_SIZE+1):\n",
    "    if (i%np.floor(TESTING_SIZE/10) == 0):\n",
    "        print(str(int(np.floor(i/np.floor(TESTING_SIZE/10))*10)), '% done')\n",
    "    \n",
    "    oimg = get_prediction_with_overlay_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
    "    oimg.save(pred_test_path + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "    gt_filename = pred_test_path + \"gt_pred_\" + str(i) + \".png\"\n",
    "    imgpred = get_predictionimage_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
    "    filenames.append(gt_filename)\n",
    "    imgpred.save(gt_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQJc6SwQRSR3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created, saved at ../submission.csv\n"
     ]
    }
   ],
   "source": [
    "masks_to_submission(submission_path, *filenames)\n",
    "print('Submission file created, saved at', submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying post-processing to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eLZKheQk3C4j",
    "outputId": "f23956e8-1a0c-46b4-afa7-0ad0c9affba8"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(postprocess_path):\n",
    "    os.mkdir(postprocess_path)\n",
    "\n",
    "post_processed_list = []\n",
    "for i in range(1,TESTING_SIZE+1): \n",
    "    p_img = get_pred_postprocessed(pred_test_path, i, 'test',IMG_PATCH_SIZE)\n",
    "    filename = postprocess_path + \"gt_pred_pp_\" + str(i) + \".png\"\n",
    "    p_img = np.asarray(p_img)\n",
    "    p_img = np.multiply(p_img,255.0)\n",
    "    p_img = Image.fromarray(p_img)\n",
    "    post_img = p_img.convert('RGB')\n",
    "    post_processed_list.append(filename)\n",
    "    post_img.save(filename)\n",
    "    \n",
    "    pred = mpimg.imread(filename)\n",
    "    imageid = \"/test_%d\" % i\n",
    "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
    "    original_img = mpimg.imread(image_filename)\n",
    "    \n",
    "    overlay = make_img_overlay(original_img, pred[:,:,0], PIXEL_DEPTH)\n",
    "    overlay.save(postprocess_path + \"overlay_pp_\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving submission file after post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created, saved at ../submission.csv\n"
     ]
    }
   ],
   "source": [
    "masks_to_submission(pp_submission_path, *post_processed_list)\n",
    "print('Submission file created, saved at', pp_submission_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
