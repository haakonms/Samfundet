{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "#import matplotlib.image as mpimg\n",
    "#import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from mask_to_submission import *\n",
    "from helpers import *\n",
    "from image_processing import *\n",
    "from image_augmentation import *\n",
    "from F1_metrics import *\n",
    "from data_context import *\n",
    "from data_extraction import *\n",
    "from prediction import *\n",
    "from keras_pred import *\n",
    "from unet_pred import *\n",
    "#from justtesting import *\n",
    "\n",
    "import code\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy import misc, ndimage\n",
    "import shutil\n",
    "\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 100\n",
    "TESTING_SIZE = 50\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 5\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000\n",
    "MAX_AUG = 1\n",
    "\n",
    "# The size of the patches each image is split into. Should be a multiple of 4, and the image\n",
    "# size would be a multiple of this. For this assignment to get the delivery correct it has to be 16\n",
    "IMG_PATCH_SIZE = 16\n",
    "CONTEXT_SIZE = 16\n",
    "\n",
    "\n",
    "# Extract data into numpy arrays, divided into patches of 16x16\n",
    "data_dir = 'data/'\n",
    "train_data_filename = data_dir + 'training/images/'\n",
    "train_labels_filename = data_dir + 'training/groundtruth/' \n",
    "test_data_filename = data_dir + 'test_set_images'\n",
    "\n",
    "# Directive for storing the augmented training images\n",
    "imgDir = data_dir + 'training/augmented/images'\n",
    "groundTruthDir = data_dir + 'training/augmented/groundtruth'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data, and set wheter it is to be augmented or not\n",
    "x_train, y_train, x_test = load_data_context(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, IMG_PATCH_SIZE, CONTEXT_SIZE, TESTING_SIZE,\n",
    "          augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir) # The last 3 parameters can be blank when we dont want augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weigths\n",
    "classes = np.array([0,1])\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,1])\n",
    "\n",
    "print('Class weights: ',class_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "#img_rows, img_cols = BATCH_SIZE, BATCH_SIZE\n",
    "img_rows = x_train[0].shape[1]\n",
    "img_cols = img_rows\n",
    "#print(img_rows)\n",
    "input_shape = (img_rows, img_cols, NUM_CHANNELS) \n",
    "\n",
    "ordering = 'channels_last'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=input_shape, padding=\"same\", data_format=ordering)) #32 is number of outputs from that layer, kernel_size is filter size, \n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(128, (2, 2), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(Conv2D(128, (2, 2), activation='relu', padding=\"same\", data_format=ordering))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_LABELS, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "          optimizer=keras.optimizers.Adam(),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "seed = 1\n",
    "\n",
    "train_rate = 0.80\n",
    "index_train = np.random.choice(x_train.shape[0],int(x_train.shape[0]*train_rate),replace=False)\n",
    "index_val  = list(set(range(x_train.shape[0])) - set(index_train))\n",
    "\n",
    "x, y = shuffle(x_train,y_train)\n",
    "x_train, y_train = x[index_train],y[index_train]\n",
    "x_val, y_val = x[index_val],y[index_val]\n",
    "print('train shape: ',x_train.shape, y_train.shape)\n",
    "print('val shape: ',x_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "# F1\n",
    "class Metrics(Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.val_f1s = []\n",
    "    #self.val_recalls = []\n",
    "    #self.val_precisions = []\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    #val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "    y_validation = self.validation_data[1]\n",
    "    y_validation = y_validation[:,1]\n",
    "    y_validation = np.squeeze(y_validation)\n",
    "    y_pred = np.asarray(self.model.predict_classes(self.validation_data[0]))\n",
    "    #print('y_validation: ', y_validation.shape)\n",
    "\n",
    "    #print('y_pred: ', y_pred.shape)\n",
    "    #tp, tn, fp, fn = f1_values(y_pred, y_validation)\n",
    "    #_val_f1 = \n",
    "    _val_f1 = f1_score(y_validation, y_pred, average='weighted')\n",
    "    #_val_recall = recall_score(val_targ, val_predict,average='micro')\n",
    "    #_val_precision = precision_score(val_targ, val_predict, average='micro')\n",
    "    self.val_f1s.append(_val_f1)\n",
    "    #self.val_recalls.append(_val_recall)\n",
    "    #self.val_precisions.append(_val_precision)\n",
    "    #print(' — val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
    "    print(' — val_f1: %f' %(_val_f1))\n",
    "    return\n",
    "\n",
    "# class Metrics(Callback):\n",
    "#     def on_epoch_end(self, batch, logs={}):\n",
    "#         predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "#         targ = self.validation_data[1]\n",
    "#         self.f1s=f1(targ, predict)\n",
    "#         return\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "\n",
    "\n",
    "# Checkpoint\n",
    "filepath=\"weights/weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [metrics,checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
    "#print(y_train[:10]) # kolonne 0 sier om den er foreground eller ikke, kolonne 1 sier om den er road eller ikke\n",
    "# Altså når man lager weights med den første kolonnen, vil man få klasse 1 = road og klasse 0 = background\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          shuffle = True,\n",
    "          verbose=1,\n",
    "          #validation_split = 0.1,\n",
    "          class_weight = class_weights,\n",
    "          callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = model.predict_classes(x_test)\n",
    "prediction_to_submission('submission_keras.csv', y_submit)\n",
    "\n",
    "\n",
    "y_train_val = model.predict_classes(x_train)\n",
    "tp, tn, fp, fn = f1_values(y_train, y_train_val)\n",
    "f1 = f1_measure(tp, fp, fn)\n",
    "print(\"f1\", f1)\n",
    "\n",
    "\n",
    "\n",
    "prediction_test_dir = \"predictions_test/\"\n",
    "if not os.path.isdir(prediction_test_dir):\n",
    "    os.mkdir(prediction_test_dir)\n",
    "for i in range(1,TESTING_SIZE+1):\n",
    "    test_data_filename = data_dir + 'test_set_images'\n",
    "\n",
    "    oimg = get_prediction_with_overlay_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
    "    oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "    filename = prediction_test_dir + \"predictimg_\" + str(i) + \".png\"\n",
    "    imgpred = get_predictionimage_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
    "    imgpred.save(filename)\n",
    "    #print(filename)\n",
    "    #image_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
