{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_model_nb.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_uedmAiL3C2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1363
        },
        "outputId": "b976865b-519c-423c-a43e-6de745ade031"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "#import matplotlib\n",
        "#matplotlib.use('Agg')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import urllib\n",
        "\n",
        "#import matplotlib.image as mpimg\n",
        "#import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from mask_to_submission import *\n",
        "from helpers import *\n",
        "from image_processing import *\n",
        "from image_augmentation import *\n",
        "from F1_metrics import *\n",
        "from data_context import *\n",
        "from data_extraction import *\n",
        "from prediction import *\n",
        "from keras_pred import *\n",
        "#from unet_pred import *\n",
        "#from justtesting import *\n",
        "\n",
        "import code\n",
        "import tensorflow.python.platform\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from scipy import misc, ndimage\n",
        "import shutil\n",
        "\n",
        "import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint, Callback\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3 # RGB images\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 2\n",
        "TRAINING_SIZE = 100\n",
        "TESTING_SIZE = 50\n",
        "VALIDATION_SIZE = 5  # Size of the validation set.\n",
        "SEED = 66478  # Set to None for random seed.\n",
        "BATCH_SIZE = 16 # 64\n",
        "NUM_EPOCHS = 20\n",
        "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
        "RECORDING_STEP = 1000\n",
        "MAX_AUG = 2\n",
        "\n",
        "# The size of the patches each image is split into. Should be a multiple of 4, and the image\n",
        "# size would be a multiple of this. For this assignment to get the delivery correct it has to be 16\n",
        "IMG_PATCH_SIZE = 16\n",
        "CONTEXT_SIZE = 16\n",
        "\n",
        "\n",
        "# Extract data into numpy arrays, divided into patches of 16x16\n",
        "data_dir = '/content/drive/My Drive/data/'\n",
        "train_data_filename = data_dir + 'training/images/'\n",
        "train_labels_filename = data_dir + 'training/groundtruth/' \n",
        "test_data_filename = data_dir + 'test_set_images'\n",
        "\n",
        "# Directive for storing the augmented training images\n",
        "imgDir = 'training/augmented/images'\n",
        "groundTruthDir = 'training/augmented/groundtruth'\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/helpers.py:9: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use('Agg')\n",
            "Using TensorFlow backend.\n",
            "/content/data_context.py:10: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use('Agg')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3tcLwM-m3C32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c4dedc49-f9f0-4bc0-8826-f4eae707baf3"
      },
      "cell_type": "code",
      "source": [
        "# Loading the data, and set wheter it is to be augmented or not\n",
        "x_train, y_train, x_test = load_data_context(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, IMG_PATCH_SIZE, CONTEXT_SIZE, TESTING_SIZE,\n",
        "          augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir, newaugment=True) # The last 3 parameters can be blank when we dont want augmentation\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting traing images...\n",
            "Loading test images\n",
            "\n",
            "Train data shape:  (311875, 48, 48, 3)\n",
            "Train labels shape:  (311875, 2)\n",
            "Test data shape:  (72200, 48, 48, 3)\n",
            "Number of samples in class 1 (background):  231336\n",
            "Number of samples in class 2 (road):  80539 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "muzLk7zL3C3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bacd433-a1ca-4ccb-982a-8b3b58740fe0"
      },
      "cell_type": "code",
      "source": [
        "# Class weigths\n",
        "classes = np.array([0,1])\n",
        "class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,1])\n",
        "\n",
        "print('Class weights: ',class_weights) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class weights:  [0.67407364 1.93617378]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NfA3idKI3C4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "047ac6e3-acb8-4fb0-f6a3-65afdf57246d"
      },
      "cell_type": "code",
      "source": [
        "# input image dimensions\n",
        "#img_rows, img_cols = BATCH_SIZE, BATCH_SIZE\n",
        "img_rows = x_train[0].shape[1]\n",
        "img_cols = img_rows\n",
        "#print(img_rows)\n",
        "input_shape = (img_rows, img_cols, NUM_CHANNELS) \n",
        "\n",
        "ordering = 'channels_last'\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=input_shape, padding=\"same\", data_format=ordering)) #32 is number of outputs from that layer, kernel_size is filter size, \n",
        "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", data_format=ordering))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(128, (2, 2), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(Conv2D(128, (2, 2), activation='relu', padding=\"same\", data_format=ordering))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", data_format=ordering))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NUM_LABELS, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               2359552   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 2,730,882\n",
            "Trainable params: 2,730,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YL-lqc7P3C4H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "          optimizer=keras.optimizers.Adam(),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uEPiNE-03C4L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''# Split train/test\n",
        "seed = 1\n",
        "\n",
        "train_rate = 0.80\n",
        "index_train = np.random.choice(x_train.shape[0],int(x_train.shape[0]*train_rate),replace=False)\n",
        "index_val  = list(set(range(x_train.shape[0])) - set(index_train))\n",
        "\n",
        "x, y = shuffle(x_train,y_train)\n",
        "x_train, y_train = x[index_train],y[index_train]\n",
        "x_val, y_val = x[index_val],y[index_val]\n",
        "print('train shape: ',x_train.shape, y_train.shape)\n",
        "print('val shape: ',x_val.shape, y_val.shape)'''\n",
        "\n",
        "\n",
        "'''# F1\n",
        "class Metrics(Callback):\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    #self.val_recalls = []\n",
        "    #self.val_precisions = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    #val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
        "    y_validation = self.validation_data[1]\n",
        "    y_validation = y_validation[:,1]\n",
        "    y_validation = np.squeeze(y_validation)\n",
        "    y_pred = np.asarray(self.model.predict_classes(self.validation_data[0]))\n",
        "    #print('y_validation: ', y_validation.shape)\n",
        "\n",
        "    #print('y_pred: ', y_pred.shape)\n",
        "    #tp, tn, fp, fn = f1_values(y_pred, y_validation)\n",
        "    #_val_f1 = \n",
        "    _val_f1 = f1_score(y_validation, y_pred, average='weighted')\n",
        "    #_val_recall = recall_score(val_targ, val_predict,average='micro')\n",
        "    #_val_precision = precision_score(val_targ, val_predict, average='micro')\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    #self.val_recalls.append(_val_recall)\n",
        "    #self.val_precisions.append(_val_precision)\n",
        "    #print(' — val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
        "    print(' — val_f1: %f' %(_val_f1))\n",
        "    return\n",
        "\n",
        "# class Metrics(Callback):\n",
        "#     def on_epoch_end(self, batch, logs={}):\n",
        "#         predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
        "#         targ = self.validation_data[1]\n",
        "#         self.f1s=f1(targ, predict)\n",
        "#         return\n",
        "\n",
        "metrics = Metrics()'''\n",
        "\n",
        "\n",
        "\n",
        "# Checkpoint\n",
        "filepath=\"/content/drive/My Drive/weights/weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RsxBSm4y3C4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "74817d96-5b71-41a7-9b9c-77552b2de5de"
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "#print(y_train[:10]) # kolonne 0 sier om den er foreground eller ikke, kolonne 1 sier om den er road eller ikke\n",
        "# Altså når man lager weights med den første kolonnen, vil man få klasse 1 = road og klasse 0 = background\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          class_weight = class_weights,\n",
        "          callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (311875, 48, 48, 3) y (311875, 2)\n",
            "Train on 280687 samples, validate on 31188 samples\n",
            "Epoch 1/20\n",
            "247600/280687 [=========================>....] - ETA: 39s - loss: 0.2828 - acc: 0.8768"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dDiZAi8l3C4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_submit = model.predict_classes(x_test)\n",
        "prediction_to_submission('submission_keras.csv', y_submit)\n",
        "\n",
        "\n",
        "y_train_val = model.predict_classes(x_train)\n",
        "tp, tn, fp, fn = f1_values(y_train, y_train_val)\n",
        "f1 = f1_measure(tp, fp, fn)\n",
        "print(\"f1\", f1)\n",
        "\n",
        "\n",
        "\n",
        "prediction_test_dir = \"predictions_test/\"\n",
        "if not os.path.isdir(prediction_test_dir):\n",
        "    os.mkdir(prediction_test_dir)\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "    test_data_filename = data_dir + 'test_set_images'\n",
        "\n",
        "    oimg = get_prediction_with_overlay_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
        "    oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "\n",
        "    filename = prediction_test_dir + \"predictimg_\" + str(i) + \".png\"\n",
        "    imgpred = get_predictionimage_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
        "    imgpred.save(filename)\n",
        "    #print(filename)\n",
        "    #image_filenames.append(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eLZKheQk3C4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}