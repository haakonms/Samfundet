{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN model from scratch\n",
    "\n",
    "This notebook is created to train the model with the CNN architecture from scratch. When the model is trained, prediction is done on the given test images, and the submission file is saved to 'submission.csv'. A post-processing step is also implemented, and the result after this is done is saved in 'submission_pp.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "_uedmAiL3C2D",
    "outputId": "e87c7016-08d6-4c7f-ebee-f26bb3a1c3c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow.python.platform\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "\n",
    "from mask_to_submission import masks_to_submission\n",
    "from cnn_pred import get_prediction_with_overlay_context, get_predictionimage_context, get_pred_postprocessed, make_img_overlay\n",
    "from data_extraction import load_data_context\n",
    "from cnn_model import create_model_cnn\n",
    "\n",
    "\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 10\n",
    "TESTING_SIZE = 50\n",
    "VALIDATION_SIZE = 10  # Size of the validation set.\n",
    "\n",
    "BATCH_SIZE = 16 \n",
    "NUM_EPOCHS = 1\n",
    "MAX_AUG = 1\n",
    "IMG_PATCH_SIZE = 16\n",
    "CONTEXT_SIZE = 16\n",
    "NOISE_LEVEL = 0.006\n",
    "\n",
    "\n",
    "'''Image paths'''\n",
    "data_dir = '../data/'\n",
    "train_data_filename = data_dir + 'training/images/'\n",
    "train_labels_filename = data_dir + 'training/groundtruth/' \n",
    "test_data_filename = data_dir + 'test_set_images'\n",
    "\n",
    "'''Path for storing the augmented training images'''\n",
    "imgDir = 'training/augmented/images'\n",
    "groundTruthDir = 'training/augmented/groundtruth'\n",
    "\n",
    "'''Path to store best weights and the submission file, and the predicted images'''\n",
    "weight_path = drive_path + 'weights/weights.best.Unet.hdf5'\n",
    "submission_path = drive_path + 'new_submission.csv'\n",
    "pred_test_path = drive_path + 'predictions_test/'\n",
    "\n",
    "'''Path to store results after post-processing'''\n",
    "postprocess_path = drive_path + 'test_set_post_images/'\n",
    "pp_submission_path = drive_path + 'kerasPostprocessedMask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3tcLwM-m3C32",
    "outputId": "7e0f17fa-ced1-46b9-df3e-140c1827cc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training images...\n",
      "Loading test images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Loading data'''\n",
    "\n",
    "x_train, y_train, x_test, x_val, y_val = load_data_context(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, VALIDATION_SIZE, IMG_PATCH_SIZE, CONTEXT_SIZE, TESTING_SIZE,\n",
    "          saltpepper = NOISE_LEVEL, augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir, newaugment=True) # The last 3 parameters can be blank when we dont want augmentation\n",
    "\n",
    "\n",
    "# Shuffle the training data\n",
    "ind_list = [i for i in range(y_train.shape[0])]\n",
    "shuffle(ind_list)\n",
    "x_train  = x_train[ind_list, :,:,:]\n",
    "y_train = y_train[ind_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "muzLk7zL3C3-",
    "outputId": "3618b12a-01d0-41a7-9d64-f67a982ac2ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  [0.70110931 1.74310505]\n"
     ]
    }
   ],
   "source": [
    "'''Computing class weights'''\n",
    "\n",
    "classes = np.array([0,1])\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,1])\n",
    "\n",
    "print('Class weights: ',class_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "NfA3idKI3C4D",
    "outputId": "751be8d3-9a3c-478b-a242-3df4bd16bc5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 252)       290556    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 252)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 252)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1161344   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,527,806\n",
      "Trainable params: 1,527,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''Loading model'''\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows = x_train[0].shape[1]\n",
    "img_cols = img_rows\n",
    "input_shape = (img_rows, img_cols, NUM_CHANNELS) \n",
    "\n",
    "model = create_model_cnn(input_shape, NUM_LABELS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YL-lqc7P3C4H"
   },
   "outputs": [],
   "source": [
    "'''Compiling model'''\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "          optimizer=Adam(),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEPiNE-03C4L"
   },
   "outputs": [],
   "source": [
    "''''Defining chechpoints to ensure the best weights are stored'''\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "RsxBSm4y3C4T",
    "outputId": "afd4ed44-2862-4504-d1d5-44735fb9c369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11250 samples, validate on 6250 samples\n",
      "Epoch 1/1\n",
      "11250/11250 [==============================] - 20s 2ms/step - loss: 0.5039 - acc: 0.7388 - val_loss: 0.6194 - val_acc: 0.5942\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59424, saving model to /content/drive/My Drive/ML_2018/weights/weights.best.Unet.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2f51be748>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Training the model'''\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          shuffle = True,\n",
    "          verbose=1,\n",
    "          class_weight = class_weights,\n",
    "          callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dDiZAi8l3C4d",
    "outputId": "ca39b98a-8f00-4475-9e98-98fb9f4adf61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making images\n"
     ]
    }
   ],
   "source": [
    "'''Ensure we do predictions using the best weights achieved during training'''\n",
    "\n",
    "model.load_weights(weight_path)\n",
    "\n",
    "\n",
    "'''Predicting on the test images, and creating overlay and groundtruth images'''\n",
    "print(\"Making images\")\n",
    "list_filename = []\n",
    "# Make images, both with predictions and overlay\n",
    "prediction_test_dir = \"predictions_test/\"\n",
    "if not os.path.isdir(prediction_test_dir):\n",
    "    os.mkdir(prediction_test_dir)\n",
    "for i in range(1,TESTING_SIZE+1):\n",
    "    test_data_filename = data_dir + 'test_set_images'\n",
    "\n",
    "    oimg = get_prediction_with_overlay_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
    "    oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "    gt_filename = prediction_test_dir + \"predictimg_\" + str(i) + \".png\"\n",
    "    imgpred = get_predictionimage_context(test_data_filename, i, 'test', model, IMG_PATCH_SIZE, CONTEXT_SIZE, PIXEL_DEPTH)\n",
    "    list_filename.append(gt_filename)\n",
    "    imgpred.save(gt_filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQJc6SwQRSR3"
   },
   "outputs": [],
   "source": [
    "'''Creating the sumbission file'''\n",
    "masks_to_submission(submission_path, *list_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eLZKheQk3C4j",
    "outputId": "f23956e8-1a0c-46b4-afa7-0ad0c9affba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created, saved at /content/drive/My Drive/ML_2018/new_submission.csv\n"
     ]
    }
   ],
   "source": [
    "'''Applying post-processing to the images'''\n",
    "\n",
    "post_processed_list = []\n",
    "if not os.path.isdir(postprocess_path):\n",
    "    os.mkdir(postprocess_path)\n",
    "\n",
    "\n",
    "for i in range(1,TESTING_SIZE+1): \n",
    "    p_img = get_pred_postprocessed(prediction_test_dir, i, 'test',IMG_PATCH_SIZE)\n",
    "    filename = postprocess_path + \"processedimg_\" + str(i) + \".png\"\n",
    "    p_img = np.array(p_img)\n",
    "    p_img = np.multiply(p_img,255.0)\n",
    "    p_img = Image.fromarray(p_img)\n",
    "    post_img = p_img.convert('RGB')\n",
    "    post_processed_list.append(filename)\n",
    "    post_img.save(filename)\n",
    "    \n",
    "    pred = mpimg.imread(filename)\n",
    "    imageid = \"/test_%d\" % i\n",
    "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
    "    original_img = mpimg.imread(image_filename)\n",
    "    \n",
    "    overlay = make_img_overlay(original_img, pred[:,:,0], PIXEL_DEPTH)\n",
    "    overlay.save(postprocess_path + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "\n",
    "\n",
    "'''Saving submission file after post-processing'''\n",
    "\n",
    "masks_to_submission(pp_submission_path, *post_processed_list)\n",
    "print('Submission file created, saved at', submission_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
